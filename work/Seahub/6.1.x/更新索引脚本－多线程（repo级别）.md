## 更新索引脚本－多线程（repo级别）

内容：6个424MB的资料库


## 物理机：

cpu： 2个

内存： 1.9G

## 测试流程

未使用多线程的流程：

```
获得所有repo和commit	->	进入更新函数（循环列表进行操作）->
->	文件比较，拿到需要增加、删除、修改的文件以及文件夹列表	->	
->	进行操作(对于增加和更新来说会先提取文件内容)

```


多线程流程：

```
获得所有repo和commit放入队列	->	生成线程，无限循环进入执行更新函数	->
->	文件比较，拿到需要增加、删除、修改的文件以及文件夹列表->	
->	进行操作(对于增加和更新来说会先提取文件内容)

```

测试结果：

--
未使用多线程：

时间：51s 		

Cpu: 只能跑到50%左右

--
使用多线程：

时间：40s

Cpu：最高到100%，但是随后就只有50%。 

--
单线程跑一个资料库

时间 ： 8s

添加索引占用7s多，其他可以忽略不计。  	

Cpu：只能跑到50%左右


## 分析：

在多线程100%的时候，主要跑的进程为pdftotext以及java的office提取进程。

然后也只有50%左右。

原因还是python的GIL限制，只能让一个CPU跑满。



## 配置优化

修改connection.py设置连接池最大为1000

修改ES默认的段合并大小

```
curl -XPUT http://localhost:9200/repofiles/settings -d '{ "persistent": { "indices.store.throttle.type": "merge", "indices.store.throttle.max_bytes_per_sec": "100mb" } }'
```

## 个人改进

可以改为多进程的方式，多进程相对来说没有GIL的限制。

多进程相对服务器来说，压力会大点，所以应该需要优化下ES服务器的配置参数.